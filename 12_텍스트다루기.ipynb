{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "12. 텍스트다루기.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMTiFThOJplGPYiZRaoJajj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luckycontrol/DeepLearning_tensorflow/blob/main/12_%ED%85%8D%EC%8A%A4%ED%8A%B8%EB%8B%A4%EB%A3%A8%EA%B8%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uC4vmoCJ99-Z"
      },
      "source": [
        "# Tokenization(토큰화) 이론\n",
        "\n",
        "텍스트 ( 문장, 문단, 문서 ) 에서 어디 까지가 문장이고 무엇이 단어인지 알려주는 것을 의미한다.\n",
        "\n",
        "- 문장 토큰화\n",
        "- 단어 토큰화\n",
        "- subword 토큰화"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lTT-ApGAcyu"
      },
      "source": [
        "## English Tokenization\n",
        "\n",
        "띄어쓰기 및 온점을 이용해 단어 및 문장에 대한 토큰화를 쉽게 진행할 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USfEQE019jix"
      },
      "source": [
        "sample_txt = \"Everywhere I turn, no matter where I look The systems in control, it's all ran by the book. I've got to get away so I can clear my mind, Xscape is what I need, Away from electric eyes.\""
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSw2hzCVBduh"
      },
      "source": [
        "문장 토큰화 (Sentence Tokenization)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9B1Ra_SBTue",
        "outputId": "4f89b7a9-ebc6-48c7-ec3c-052658841390",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tokenized_sentece = sample_txt.split(', ')\n",
        "tokenized_sentece"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Everywhere I turn',\n",
              " 'no matter where I look The systems in control',\n",
              " \"it's all ran by the book. I've got to get away so I can clear my mind\",\n",
              " 'Xscape is what I need',\n",
              " 'Away from electric eyes.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlBbDcb1CDzI"
      },
      "source": [
        "단어 토큰화 (Word Tokenization)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNcRIujVBrfI",
        "outputId": "6a6f1450-e3db-4dbf-e553-dec732c49771",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tokenized_word = sample_txt.split()\n",
        "tokenized_word"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Everywhere',\n",
              " 'I',\n",
              " 'turn,',\n",
              " 'no',\n",
              " 'matter',\n",
              " 'where',\n",
              " 'I',\n",
              " 'look',\n",
              " 'The',\n",
              " 'systems',\n",
              " 'in',\n",
              " 'control,',\n",
              " \"it's\",\n",
              " 'all',\n",
              " 'ran',\n",
              " 'by',\n",
              " 'the',\n",
              " 'book.',\n",
              " \"I've\",\n",
              " 'got',\n",
              " 'to',\n",
              " 'get',\n",
              " 'away',\n",
              " 'so',\n",
              " 'I',\n",
              " 'can',\n",
              " 'clear',\n",
              " 'my',\n",
              " 'mind,',\n",
              " 'Xscape',\n",
              " 'is',\n",
              " 'what',\n",
              " 'I',\n",
              " 'need,',\n",
              " 'Away',\n",
              " 'from',\n",
              " 'electric',\n",
              " 'eyes.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_QKrDXeC95i"
      },
      "source": [
        "## 띄어쓰기로 영어 문장 내 단어 구분할 때의 문제점\n",
        "* We're Genius!!\n",
        "* We are Genius!\n",
        "* We are Genius\n",
        "\n",
        "우리는 위 세 문장이 모두 같은 의미라는 것을 알지만, 기계는 그렇지 않다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1qg_b8_Dek8"
      },
      "source": [
        "## 해결방법 첫 번째 - 특수문자 지우기\n",
        "\n",
        "* `[We, re, Genius]`\n",
        "* `[We, are, Genius]`\n",
        "* `[We, are, Genius]`\n",
        "\n",
        "특수문자가 중요한 의미를 가지는 경우에도 특수문자를 삭제하는게 맞을까?\n",
        "* $12.45 -> `[12, 45]`\n",
        "* Mr. So -> `[Mr, So]`\n",
        "* Mrs. Kim -> `[Mrs, Kim]`\n",
        "* 192.168.0.1 -> `[192, 168, 0, 1]`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcMGAGbsEz9i"
      },
      "source": [
        "## 영어 단어 토크나이저 활용하기\n",
        "\n",
        "* TreebankWordTokenizer 패키지가 있다.\n",
        "  - 영어 표준 토큰화 규격을 따라간다.\n",
        "  - Fenn Treebank Tokenization 규칙\n",
        "\n",
        "* TreebankWordTokenizer의 규칙\n",
        "  - 하이픈으로 구성된 단어는 하나로 유지\n",
        "  - doesn't 같이 어퍼스트로피로 '접어'가 함께하는 단어는 따로 분리 해준다.\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_qKAelzEzqR"
      },
      "source": [
        "## 한국어 토큰화가 어려운 이유!\n",
        "\n",
        "1. 한국어는 교착어이다.\n",
        "2. 한국어는 띄어쓰기가 잘 안지켜진다.\n",
        "3. 한국어는 주어생략이 가능하고 어순도 중요하지 않다.\n",
        "4. 한자어라는 특성상 하나의 음절도 다른 의미를 가질 수 있다.\n",
        "\n",
        "### 교착어\n",
        "실질적인 의미를 가지는 어간에 조사나 어미와 같은 문법 형태소가 결합해서 문법적인 기능(각각 다른 의미를 갖는)이 부여되는 언어\n",
        "ex) 책상 + 은,는,이,가 \n",
        "\n",
        "### 띄어쓰기 문제\n",
        "> 거지같이띄어쓰기를하지않아도읽는데문제가없다.   \n",
        "> Thisishardtoreadyouknow\n",
        "\n",
        "`py-hanspell` 패키지 또는 `ko-spacing` 패키지를 이용해 문법이나 띄어쓰기 교정을 할 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxjpWSgoCOHH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}